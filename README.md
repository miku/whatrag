# Ouroboros

> [Ouroboros](https://en.wikipedia.org/wiki/Ouroboros), or how to build a
> retrieval-augmented data generative AI pipeline from scratch

![](static/Chrysopoea.png)

A large language model can be flaky, but they are amazing
[compressors](https://arxiv.org/pdf/2309.10668.pdf). How do we use them
approriately and efficiently?

> Countless hours spent searching for documentation on peculiar, intellectually
> uninteresting aspects; the efforts to learn an overly complicated API, often
> without good reason; writing immediately usable programs that I would discard
> after a few hours. These are all things I do not want to do, especially now,
> with Google having become a sea of spam in which to hunt for a few useful
> things. -- [http://antirez.com/news/140](http://antirez.com/news/140)

[...]

> I have also learned that LLMs are a bit like Wikipedia and all the video
> courses scattered on YouTube: **they help those with the will, ability, and
> discipline**, but they are of marginal benefit to those who have fallen behind.

How do we learn, when and how to use this technology?

> Have a peek at this blog post that is going around lately: [The pain points
> of building a copilot](https://austinhenley.com/blog/copilotpainpoints.html)
> These people are brimming with excitement about all the new problems that
> LLMs are bringing to the table. -- [Why We Can't Have Nice Software](https://andrewkelley.me/post/why-we-cant-have-nice-software.html)

[LeCun on 2023-02-13](https://twitter.com/ylecun/status/1625118108082995203) (780.8K views as of 2024-02-06, [archived](https://web.archive.org/web/20230213173604/https://twitter.com/ylecun/status/1625118108082995203)):

> My unwavering opinion on current (auto-regressive) LLMs
> 1. They are useful as writing aids.
> 3. They make stuff up or retrieve stuff approximately.
> 6. Current LLMs should be used as writing aids, not much more.
> 7. Marrying them with tools such as search engines is highly non trivial.
> 8. There will be better systems that are factual, non toxic, and controllable. They just won't be auto-regressive LLMs.
> [...]
> 10. Warning folks that AR-LLMs make stuff up and should not be used to get factual advice.
> 11. Warning that only a small superficial portion of human knowledge can ever be captured by LLMs.
> 12. Being clear that better system will be appearing, but they will be based on different principles. They will not be auto-regressive LLMs.
> [...]


